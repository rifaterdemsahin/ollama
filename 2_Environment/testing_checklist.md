# ðŸ§ª Testing Checklist â€” Stage 2: Environment

> **YouTube Reference:** [Ollama Installation Guide](https://www.youtube.com/results?search_query=ollama+local+llm+installation+guide) â€” Step-by-step Ollama setup across platforms.

## âœ… Ollama Installation

### macOS
- [ ] `brew install ollama` or curl installer executed successfully
- [ ] `ollama --version` returns a version number
- [ ] `ollama serve` starts without errors on port 11434
- [ ] `ollama pull llama3.2` completes successfully
- [ ] `ollama run llama3.2 "Hello"` returns a response

### Linux
- [ ] `curl -fsSL https://ollama.com/install.sh | sh` runs successfully
- [ ] systemd service starts and is enabled
- [ ] Port 11434 is accessible

### Windows
- [ ] Installer downloaded and executed
- [ ] Ollama runs in system tray
- [ ] Port 11434 accessible from browser

## âœ… Qdrant Vector Database

- [ ] Docker installed and running
- [ ] `docker pull qdrant/qdrant` succeeds
- [ ] Qdrant container starts on ports 6333/6334
- [ ] Qdrant dashboard accessible at `http://localhost:6333/dashboard`
- [ ] API endpoint responds at `http://localhost:6333/collections`

## âœ… nomic-embed-text

- [ ] `ollama pull nomic-embed-text` completes
- [ ] Embedding API call returns 4096-dimension vector
- [ ] Embeddings can be stored in Qdrant collection

## âœ… AI Client Configuration

- [ ] Ollama API endpoint accessible at `http://localhost:11434`
- [ ] `claude.md` persona rules defined
- [ ] Obsidian shortcut title generation via Ollama tested

## ðŸ“Š Environment Validation

| Component | Expected | Verified |
|-----------|----------|----------|
| Ollama | Running on :11434 | ðŸ”² |
| Qdrant | Running on :6333 | ðŸ”² |
| nomic-embed-text | Loaded, 4096 dims | ðŸ”² |
| Docker | Running | ðŸ”² |

## ðŸ”— Related Pages

- [Real Unknown (Why?) â†’](../1_Real_Unknown/index.html)
- [Formula (How?) â†’](../4_Formula/index.html)
- [View Readme Source](../markdown_renderer.html?file=2_Environment/readme.md)
